{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import casadi as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f563cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrictSQPSolver:\n",
    "    def __init__(self, f_func, h_func=None, g_func=None, max_iter=50, tol=1e-6, use_bfgs=False, verbose=False, only_feasible_steps=False):\n",
    "        self.f_func = f_func\n",
    "        self.h_func = h_func\n",
    "        self.g_func = g_func\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.use_bfgs = use_bfgs\n",
    "        self.verbose = verbose\n",
    "        self.trace = []\n",
    "        self.only_feasible_steps = only_feasible_steps\n",
    "\n",
    "        self.x_dim = f_func.size_in(0)[0]\n",
    "        self._setup_derivatives()\n",
    "\n",
    "    def _setup_derivatives(self):\n",
    "        x = ca.MX.sym('x', self.x_dim)\n",
    "        self.grad_f = ca.Function('grad_f', [x], [ca.gradient(self.f_func(x), x)])\n",
    "\n",
    "        if self.h_func is not None:\n",
    "            self.grad_h = ca.Function('grad_h', [x], [ca.jacobian(self.h_func(x), x)])\n",
    "        if self.g_func is not None:\n",
    "            self.grad_g = ca.Function('grad_g', [x], [ca.jacobian(self.g_func(x), x)])\n",
    "\n",
    "        lmbda_dim = 0\n",
    "        if self.g_func is not None:\n",
    "            lmbda_dim += self.g_func(x).size1()\n",
    "        if self.h_func is not None:\n",
    "            lmbda_dim += self.h_func(x).size1()\n",
    "\n",
    "        lmbda = ca.MX.sym('lmbda', lmbda_dim)\n",
    "        L = self.f_func(x)\n",
    "        idx = 0\n",
    "        self.num_equality_constraints = 0\n",
    "        self.num_inequality_constraints = 0\n",
    "\n",
    "        if self.g_func is not None:\n",
    "            g_val = self.g_func(x)\n",
    "            self.num_equality_constraints = g_val.size1()\n",
    "            for i in range(self.num_equality_constraints):\n",
    "                L += lmbda[idx] * g_val[i]\n",
    "                idx += 1\n",
    "            \n",
    "        if self.h_func is not None:\n",
    "            h_val = self.h_func(x)\n",
    "            self.num_inequality_constraints = h_val.size1()\n",
    "            for i in range(self.num_inequality_constraints):\n",
    "                L += lmbda[idx] * h_val[i]\n",
    "                idx += 1\n",
    "\n",
    "        self.lagrangian = ca.Function('lagrangian', [x, lmbda], [L])\n",
    "        self.grad_lagrangian = ca.Function('grad_lagrangian', [x, lmbda], [ca.gradient(L, x)])\n",
    "        self.hess_L = ca.Function('hess_L', [x, lmbda], [ca.hessian(L, x)[0]])\n",
    "    \n",
    "        self.constraint_violation = ca.Function('constr_violation', [x], \n",
    "                                              [self._calculate_constraint_violation(x)])\n",
    "\n",
    "    def _calculate_constraint_violation(self, x):\n",
    "        \"\"\"Calculate the constraint violation for merit function.\"\"\"        \n",
    "        violations = []\n",
    "        \n",
    "        if self.g_func is not None:\n",
    "            g_val = self.g_func(x)\n",
    "            for i in range(g_val.size1()):\n",
    "                violations.append(ca.fabs(g_val[i]))\n",
    "                \n",
    "        if self.h_func is not None:\n",
    "            h_val = self.h_func(x)\n",
    "            for i in range(h_val.size1()):\n",
    "                violations.append(ca.fmax(0, -h_val[i]))\n",
    "                \n",
    "        if violations:\n",
    "            return ca.sum1(ca.vertcat(*violations))\n",
    "        else:\n",
    "            return ca.MX(0)\n",
    "\n",
    "    def solve(self, x0):\n",
    "        x_k = np.array(x0).flatten()\n",
    "        lambda_k = np.zeros(self.num_equality_constraints + self.num_inequality_constraints)\n",
    "        # Initialize lambda_k with a positive value for inequality constraints\n",
    "        lambda_k[self.num_equality_constraints:] = 1.0\n",
    "        \n",
    "        H_k = np.eye(self.x_dim)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            print(f\"lambda_k: {lambda_k}\")\n",
    "            self.trace.append(x_k.copy())\n",
    "\n",
    "            grad_f_k = np.array(self.grad_f(x_k).full()).flatten()\n",
    "\n",
    "            g_val_k, grad_g_k = None, None\n",
    "            h_val_k, grad_h_k = None, None\n",
    "            if self.g_func is not None:\n",
    "                g_val_k = np.array(self.g_func(x_k).full()).flatten()\n",
    "                grad_g_k = np.array(self.grad_g(x_k).full())\n",
    "            if self.h_func is not None:\n",
    "                h_val_k = np.array(self.h_func(x_k).full()).flatten()\n",
    "                grad_h_k = np.array(self.grad_h(x_k).full())\n",
    "\n",
    "            if not self.use_bfgs:\n",
    "                H_k = np.array(self.hess_L(x_k, lambda_k).full())\n",
    "                # Make sure H_k is symmetric, it should be theoretically but does not have to be numerically\n",
    "                H_k = (H_k + H_k.T) / 2\n",
    "\n",
    "                eigvals = np.linalg.eigvalsh(H_k)\n",
    "                min_eig = np.min(eigvals)\n",
    "                if min_eig <= 1e-6:\n",
    "                    H_k += (abs(min_eig) + 1e-4) * np.eye(H_k.shape[0])\n",
    "\n",
    "            # Solve QP\n",
    "            success, d_k, multipliers = self._solve_qp(\n",
    "                H_k,\n",
    "                grad_f_k,\n",
    "                grad_g_k,\n",
    "                g_val_k if g_val_k is not None else None,\n",
    "                grad_h_k,\n",
    "                h_val_k if h_val_k is not None else None\n",
    "            )\n",
    "\n",
    "            if not success:\n",
    "                if self.verbose:\n",
    "                    print(f\"[Iter {iteration}] QP solver failed, early stop.\")\n",
    "                break\n",
    "\n",
    "            if np.linalg.norm(d_k) < self.tol:\n",
    "                self.trace.append(x_k + d_k[:self.x_dim])\n",
    "                if self.verbose:\n",
    "                    print(f\"[Iter {iteration}] Converged, step norm={np.linalg.norm(d_k):.2e}\")\n",
    "                break\n",
    "\n",
    "            # Line search (backtracking)\n",
    "            alpha = 0.9\n",
    "            beta = 0.5\n",
    "            c1 = 1e-4\n",
    "            lagrangian_current = self.lagrangian(x_k, lambda_k).full().flatten()[0]\n",
    "            lagrangian_grad_current = np.array(self.grad_lagrangian(x_k, lambda_k).full()).flatten()\n",
    "\n",
    "            while True:\n",
    "                x_trial = x_k + alpha * d_k\n",
    "                lambda_trial = multipliers\n",
    "                lagrangian_trial = self.lagrangian(x_trial, lambda_trial).full().flatten()[0]\n",
    "\n",
    "                if self.constraint_violation(x_trial).full().flatten()[0] <= 1e-6 or not self.only_feasible_steps:\n",
    "                    if lagrangian_trial <= lagrangian_current + c1 * alpha * np.dot(lagrangian_grad_current, d_k):\n",
    "                        break\n",
    "                alpha *= beta\n",
    "                if alpha < 1e-8:\n",
    "                    break\n",
    "\n",
    "            x_next = x_k + alpha * d_k\n",
    "            # Use the multipliers from the QP solver\n",
    "            lambda_next = multipliers\n",
    "\n",
    "            if self.use_bfgs:\n",
    "                s = (x_next - x_k).reshape(-1, 1)\n",
    "                y = (np.array(self.grad_f(x_next).full()).flatten() - grad_f_k).reshape(-1, 1)\n",
    "                rho = 1.0 / (y.T @ s + 1e-8)\n",
    "                V = np.eye(self.x_dim) - rho * s @ y.T\n",
    "                H_k = V @ H_k @ V.T + rho * s @ s.T\n",
    "\n",
    "            x_k = x_next\n",
    "            lambda_k = lambda_next\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"[Iter {iteration}] Cost: {lagrangian_current:.6f}, alpha={alpha:.3f}, step norm={np.linalg.norm(d_k):.2e}\")\n",
    "\n",
    "        return x_k\n",
    "\n",
    "    def _solve_qp(self, H, f, A_eq, b_eq, A_ineq, b_ineq):\n",
    "        x = ca.MX.sym('x', H.shape[1])\n",
    "        f = f.reshape((1, -1))\n",
    "        cost = 0.5 * ca.mtimes([x.T, H, x]) + ca.mtimes(f, x)\n",
    "\n",
    "        constraints = []\n",
    "        lbg = []\n",
    "        ubg = []\n",
    "\n",
    "        if A_eq is not None and A_eq.shape[0] > 0:\n",
    "            constraints.append(ca.mtimes(A_eq, x) + b_eq)\n",
    "            lbg.append(np.zeros(A_eq.shape[0]))\n",
    "            ubg.append(np.zeros(A_eq.shape[0]))\n",
    "\n",
    "        if A_ineq is not None and A_ineq.shape[0] > 0:\n",
    "            constraints.append(ca.mtimes(A_ineq, x) + b_ineq)\n",
    "            lbg.append(np.zeros(A_ineq.shape[0]))\n",
    "            ubg.append(np.full(A_ineq.shape[0], np.inf))\n",
    "\n",
    "        if constraints:\n",
    "            g = ca.vertcat(*constraints)\n",
    "            lbg = np.concatenate(lbg)\n",
    "            ubg = np.concatenate(ubg)\n",
    "        else:\n",
    "            g = ca.MX()\n",
    "            lbg = np.array([])\n",
    "            ubg = np.array([])\n",
    "\n",
    "        qp = {'x': x, 'f': cost, 'g': g}\n",
    "        solver = ca.qpsol('solver', 'qpoases', qp, {'error_on_fail': False})\n",
    "        sol = solver(lbg=lbg, ubg=ubg)\n",
    "\n",
    "        stats = solver.stats()\n",
    "        success = not bool(stats['return_status'] == 'Infeasible_Problem_Detected')\n",
    "\n",
    "        # return success, np.array(sol['x'].full()).flatten(), np.array(sol['lam_g'].full()).flatten()\n",
    "        return success, np.array(sol['x'].full()).flatten(), np.array(sol['lam_g'].full()).flatten()\n",
    "\n",
    "\n",
    "    def plot_trajectory(self, global_minima=None):\n",
    "        x_max, x_min, y_max, y_min = 2.5, -2.5, 2.5, -2.5\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.f_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        if self.h_func is not None:\n",
    "            H_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    H_vals[i, j] = self.h_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, H_vals, levels=[0], colors='k', linewidths=2, linestyles='--')\n",
    "\n",
    "        if self.g_func is not None:\n",
    "            G_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    G_vals[i, j] = self.g_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, G_vals, levels=[0], colors='b', linewidths=2)\n",
    "            ax.contourf(X, Y, G_vals, levels=[-np.inf, 0], colors='blue', alpha=0.5)\n",
    "\n",
    "        if self.trace:\n",
    "            traj = np.array(self.trace)\n",
    "            ax.plot(traj[:, 0], traj[:, 1], 'o-', color='orange', label='SQP Trajectory')\n",
    "            ax.plot(traj[0, 0], traj[0, 1], 'bo', label='Start')\n",
    "            ax.plot(traj[-1, 0], traj[-1, 1], 'gs', label='End')\n",
    "\n",
    "        if global_minima is not None:\n",
    "            ax.plot(global_minima[0], global_minima[1], '*', color='red', markersize=15, label='Global Min')\n",
    "\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_xlabel('$x_0$')\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_title(\"Strict SQP Optimization Trajectory\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee47bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbols\n",
    "x = ca.MX.sym('x', 2)\n",
    "\n",
    "# Objective: simple quadratic\n",
    "f = ca.Function('f', [x], [0.5 * (x[0]**2 / 4 + x[1]**2)])\n",
    "\n",
    "# Equality constraint: nonlinear\n",
    "g = None # ca.Function('g', [x], [x[0] + ca.sin(x[1]) - 1])\n",
    "\n",
    "# Inequality constraint: elliptical region\n",
    "h = ca.Function('h', [x], [1 - (x[0] - 1)**2 - (x[1] - 1.5)**2 / 2])\n",
    "\n",
    "# Instantiate solver\n",
    "sqp_solver = StrictSQPSolver(\n",
    "    f_func=f,\n",
    "    h_func=h,\n",
    "    g_func=g,\n",
    "    max_iter=50,\n",
    "    tol=1e-6,\n",
    "    use_bfgs=False,\n",
    "    only_feasible_steps=True,  # if True, only feasible step sizes are accepted\n",
    "    verbose=True \n",
    ")\n",
    "\n",
    "# Initial point\n",
    "x_init = np.array([1.8, 2.0])\n",
    "\n",
    "# Solve\n",
    "sol = sqp_solver.solve(x_init)\n",
    "\n",
    "print(\"Optimal Solution Found:\", sol)\n",
    "\n",
    "# Plot\n",
    "sqp_solver.plot_trajectory(global_minima=np.array([0.0, 0.0]))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
