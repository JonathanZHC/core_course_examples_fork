{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b43ac0",
   "metadata": {},
   "source": [
    "\n",
    "### **Chapter 3: Optimization Fundamentals**\n",
    "\n",
    "\n",
    "In this chapter, we introduce optimization problems under both unconstrained and constrained settings. We begin with unconstrained optimization, presenting several commonly used solving methods, accompanied by solver implementations in code. These methods will be tested across a variety of examples to illustrate their respective performance characteristics. Subsequently, we extend the discussion to constrained optimization problems. Utilizing CasADi’s symbolic framework, we store symbolic expressions and leverage its built-in solvers (e.g., qpOASES) to solve the problems and visualize the results. The theoretical foundations and implementation techniques introduced in this chapter will serve as the basis for subsequent chapters, such as those focusing on Model Predictive Control (MPC).\n",
    "\n",
    "All the contents are summarized in the table below.  \n",
    "\n",
    "<table border=\"1\" style=\"border-collapse: collapse; text-align: center;\">\n",
    "  <!-- Title Row -->\n",
    "  <tr>\n",
    "    <th colspan=\"2\" style=\"text-align:center\">Content of Chapter 3 Exercise</th>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 1 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"5\">Unconstrained Optimization</td>\n",
    "    <td>Example 1.1: implement the solver for unconstrained optimization problems</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 1.2: use Gradient-descent method to optimize Quadratic objective function</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 1.3: use Gradient-descent method to optimize Rosenbrock objective function</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 1.4: use Newton method to optimize Rosenbrock objective function</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 1.5: use Newton method to optimize Rastrigin objective function</td>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 2 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"4\">Constrained Optimization</td>\n",
    "    <td>Example 2.1: configurate the solver for QP problems</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 2.2: use QP solver to optimize quadratic objective function with linear constraint</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 3.1: configurate the solver for NLP problems</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 3.2: use SQP solver to optimize quadratic objective function with nonlinear constraint</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "First, we need to import relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a30bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import casadi as ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df27691",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Problem Definition:**\n",
    "\n",
    "A generic optimization problem has the following form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x} \\quad & f(x) \\\\\\\\\n",
    "\\text{subject to} \\quad & h_i(x) = 0, \\quad \\forall i \\in \\{1, 2, \\dots, N\\}, \\\\\\\\\n",
    "& g_j(x) \\leq 0, \\quad \\forall j \\in \\{1, 2, \\dots, M\\},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $ x \\in \\mathbb{R}^n $ is the **optimization variable** of the problem, $ f : \\mathbb{R}^n \\mapsto \\mathbb{R} $ is the **objective function**, and $ h_i : \\mathbb{R}^n \\mapsto \\mathbb{R} $ and $ g_j : \\mathbb{R}^n \\mapsto \\mathbb{R} $ are the *equality* and **inequality constraint functions**, respectively. The objective function and the constraint functions can be general nonlinear functions. In this chapter, we generally assume that $ f $, $ h_i $, and $ g_j $ are differentiable functions.\n",
    "\n",
    "##### **Subclasses of optimization problems:**\n",
    "\n",
    "   1\\) **Unconstrained Optimization:**  A general optimization problem without any constraints is called an unconstrained optimization problem. In this case, the goal is to find a minimizer of the objective function without being restricted by any equality or inequality conditions.\n",
    "\n",
    "   2\\) **Linear Programming (LP):** An optimization problem is called a linear program if both the objective function and all the constraint functions are linear. Specifically, the objective is a linear function of the decision variables, and the feasible set is defined by linear equality and inequality constraints.\n",
    "\n",
    "   3\\) **Quadratic Programming (QP):** An optimization problem is called a quadratic program if the objective function is quadratic and the constraints are linear. That is, the objective function includes a quadratic term, while the equality and inequality constraints are affine functions of the decision variables.\n",
    "\n",
    "   4\\) **Nonlinear Programming (NLP):** A general optimization problem with at least one nonlinear function, either in the objective function, the inequality constraints, or the equality constraints, is called a nonlinear program. In a nonlinear program, the functions involved can be nonlinear, and solving such problems typically requires iterative numerical methods.\n",
    "\n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6223f",
   "metadata": {},
   "source": [
    "\n",
    "### **Part (a): unconstrained optimization**\n",
    "\n",
    "As discussed above, unconstrained optimization primarily follows the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x} \\quad & f(x) \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the objective function is typically selected from several standard forms. In the exercises of this chapter, we primarily use the following three objective functions as test cases:\n",
    "\n",
    "1) **Quadratic Function:** A simple convex function used as a basic test case for optimization algorithms.\n",
    "\n",
    "$$\n",
    "f(x) = \\left(\\frac{x_0}{2}\\right)^2 + x_1^2, \\quad x^* = [0, 0]\n",
    "$$\n",
    "\n",
    "2) **Rosenbrock Function:** A non-convex function used to test the performance of optimization algorithms, characterized by a narrow, curved valley leading to the global minimum.\n",
    "\n",
    "$$\n",
    "f(x) = (1 - x_0)^2 + 100 (x_1 - x_0^2)^2, \\quad x^* = [1, 0]\n",
    "$$\n",
    "\n",
    "3) **Rastrigin Function:** A highly multimodal function used to test the ability of algorithms to escape local minima, combining a quadratic term with a cosine modulation.\n",
    "\n",
    "$$\n",
    "f(x) = 20 + \\left( x_0^2 - 10 \\cos(2\\pi x_0) \\right) + \\left( x_1^2 - 10 \\cos(2\\pi x_1) \\right), \\quad x^* = [0, 0]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def quadratic(x):\n",
    "    return 1/2*(x[0]**2/4 + x[1]**2)\n",
    "\n",
    "def rosenbrock(x):\n",
    "    return (1 - x[0])**2 + 100*(x[1] - x[0]**2)**2\n",
    "\n",
    "def rastrigin_setup(pkg):\n",
    "    def rastrigin(x):\n",
    "        return 20 + (x[0]**2 - 10*pkg.cos(2*np.pi*x[0])) + (x[1]**2 - 10*pkg.cos(2*np.pi*x[1]))\n",
    "    return rastrigin\n",
    "\n",
    "def plot_function(func, x_range, y_range):\n",
    "    x = np.linspace(x_range[0], x_range[1], 100)\n",
    "    y = np.linspace(y_range[0], y_range[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = func(np.array([X, Y]))\n",
    "    return X, Y, Z\n",
    "\n",
    "functions = [quadratic, rosenbrock, rastrigin_setup(np)]\n",
    "\n",
    "# Create 3D plots for each function\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Define appropriate ranges for each function\n",
    "ranges = [\n",
    "    [(-4.5, 4.5), (-4.5, 4.5)],       # Quadratic\n",
    "    [(-2, 2), (-1, 3)],               # Rosenbrock\n",
    "    [(-5.12, 5.12), (-5.12, 5.12)]    # Rastrigin\n",
    "]\n",
    "\n",
    "titles = [\"Quadratic Function\", \"Rosenbrock Function\", \"Rastrigin Function\"]\n",
    "\n",
    "for i, (func, (x_range, y_range), title) in enumerate(zip(functions, ranges, titles)):\n",
    "    ax = fig.add_subplot(1, 3, i+1, projection='3d')\n",
    "    X, Y, Z = plot_function(func, x_range, y_range)\n",
    "    \n",
    "    # Create the surface plot\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8, \n",
    "                          linewidth=0, antialiased=True)\n",
    "    \n",
    "    # Add a contour plot at the bottom\n",
    "    cset = ax.contour(X, Y, Z, zdir='z', offset=np.min(Z), cmap='viridis')\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('f(X,Y)')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Add colorbar\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31fb37",
   "metadata": {},
   "source": [
    "\n",
    "#### **Algorithms for Unconstrained Optimization:**\n",
    "\n",
    "The process of finding the optimal solution to an unconstrained optimization problem can generally be divided into two main steps: \n",
    " - Step 1: determining the search direction to perform one step of update, with common methods including gradient descent and Newton's method;\n",
    " - Step 2: performing a line search along the chosen direction to find an appropriate step size, where backtracking is one of the simplest and most widely used strategies.  \n",
    "\n",
    "In the following, we will briefly introduce these algorithms.\n",
    "\n",
    "##### **Gradient descent**\n",
    "\n",
    "Gradient descent (GD) is a first-order iterative optimization algorithm for finding the local minimum of a differentiable function.\n",
    "At each iteration, it updates the current estimate by moving in the direction of the steepest descent, which is the negative gradient of the function at that point.\n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\alpha_k \\nabla f(x_k)\n",
    "$$\n",
    "\n",
    "where:\n",
    "   - $x_k$ is the current iterate,\n",
    "   - $\\nabla f(x_k)$ is the gradient of the objective function at $x_k$,\n",
    "   - $\\alpha_k > 0$ is the step size (or learning rate), which can be determined via a line search strategy.\n",
    "\n",
    "Gradient Descent guarantees convergence to a local minimum for convex functions under appropriate conditions on the step size. However, it's also highly sensitive to the choice of step size—too small leads to slow convergence, while too large may cause divergence—and its inefficiency on ill-conditioned problems, where the optimization path can become highly zigzagged and slow.\n",
    "\n",
    "\n",
    "##### **Newton method**\n",
    "\n",
    "Newton's Method is a second-order optimization algorithm that uses both the gradient and the Hessian (second derivative) of the objective function to find a local minimum.\n",
    "At each iteration, it updates the current estimate by moving along the Newton direction, which accounts for the local curvature of the function.\n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\alpha_k \\left[\\nabla^2 f(x_k)\\right]^{-1} \\nabla f(x_k)\n",
    "$$\n",
    "\n",
    "where $\\nabla^2 f(x_k)$ is the Hessian matrix of the objective function at $x_k$.\n",
    "\n",
    "\n",
    "When the Hessian is positive definite and the initial guess is sufficiently close to the minimizer, Newton's Method achieves quadratic convergence, making it significantly faster than first-order methods like gradient descent near the solution.\n",
    "\n",
    "\n",
    "\n",
    "##### **Line search (backtracking)**\n",
    "\n",
    "Line search is a subroutine in optimization algorithms that determines an appropriate step size along a given search direction. The goal is to ensure sufficient decrease in the objective function while avoiding overly small steps. One of the most common and simple methods is **Backtracking Line Search**. It starts with a relatively large initial step size and repeatedly reduces it until a sufficient decrease condition (typically the **Armijo condition**) is satisfied. The pseudocode of the algorithm is shown below:\n",
    "\n",
    " - Start with an initial step size $\\alpha = \\alpha_0$ (typically $\\alpha_0 = 1$).\n",
    " - Check whether the **Armijo condition** holds: $f(x_k + \\alpha p_k) \\leq f(x_k) + c \\alpha \\nabla f(x_k)^T p_k$, where $c \\in (0,1)$ is a small constant (e.g., $10^{-4}$).\n",
    " - If the condition is not satisfied, shrink the step size by a factor $\\beta \\in (0,1)$ (e.g., $\\beta = 0.5$), that is, update $\\alpha \\leftarrow \\beta \\alpha$, and repeat the check.\n",
    " - Continue until the Armijo condition is satisfied.\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b72687",
   "metadata": {},
   "source": [
    "#### **Example 1.1: implement the solver for unconstrained optimization problems**  \n",
    "\n",
    "Based on the three algorithms introduced above, we now implement a solver for unconstrained optimization problems, which uses GD or Newton's method as the direction search algorithm, and applies the backtracking of the line search algorithm to determine a suitable step size. The implementation of the solver will follow the steps below:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;1\\) Initialize the algorithm parameters, including the starting point of the iteration $x_0$ and the line search parameters such as $\\alpha_0$, $\\beta$, and $c$;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2\\) Use the CasADi symbolic system to define the symbolic variable $x$, and construct the expressions for the objective functions: Quadratic, Rosenbrock, and Rastrigin;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3\\) Use automatic differentiation (Autodiff) to compute the Jacobian and Hessian of the objective function;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;4\\) Implement the main iteration loop:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i\\) Based on the precomputed Jacobian and Hessian information, determine the search direction using either Gradient Descent or Newton’s method;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ii\\) Use backtracking line search starting from $\\alpha_0$, progressively reducing the step size to find the largest \n",
    "$\\alpha$ that satisfies the Armijo condition;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; iii\\) Perform one iteration based on the search direction and step size, and check whether the convergence criterion is satisfied.\n",
    "\n",
    "*Note that: for the symbolic framework, please check out this material https://web.casadi.org/docs/#document-symbolic*. *Section 3.3 shows how to define the symbolic variables.*  *Section 3.9 shows how to use the automatic differentiation to solve the Jacobian and Hessian.*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0db6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnconstrOptimizer:\n",
    "    def __init__(self, alpha_0 = 1.0, beta = 0.5, c = 1e-4):\n",
    "\n",
    "        self.func_flag = 'quadratic'\n",
    "\n",
    "        self.x_init = np.array([0.0, 0.0])\n",
    "\n",
    "        self.solution_trajectory = []\n",
    "        self.directions = []\n",
    "\n",
    "        self.x = ca.MX.sym('x', 2)\n",
    "        \n",
    "        # Hyperparameters for line search\n",
    "        self.alpha_0 = alpha_0\n",
    "        self.beta = beta\n",
    "        self.c = c\n",
    "\n",
    "    def set_objective(self, func_type='quadratic'):\n",
    "        self.func_flag = func_type\n",
    "\n",
    "        if func_type == 'quadratic':\n",
    "            expr = quadratic(self.x)\n",
    "            self.global_minima = np.array([0.0, 0.0])\n",
    "\n",
    "        elif func_type == 'rosenbrock':\n",
    "            expr = rosenbrock(self.x)\n",
    "            self.global_minima = np.array([1.0, 1.0])\n",
    "\n",
    "        elif func_type == 'rastrigin':\n",
    "            rastrigin = rastrigin_setup(ca)\n",
    "            expr = rastrigin(self.x)\n",
    "            self.global_minima = np.array([0.0, 0.0])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown function type.\")\n",
    "\n",
    "        self.expr = expr\n",
    "        self.f = ca.Function('f', [self.x], [expr])\n",
    "        self.grad_f = ca.Function('grad_f', [self.x], [ca.gradient(expr, self.x)])\n",
    "        self.hess_f = ca.Function('hess_f', [self.x], [ca.hessian(expr, self.x)[0]])\n",
    "\n",
    "    def solve(self, x_init, method='gd', max_step=100, tol=1e-6):\n",
    "\n",
    "        self.x_init = np.array(x_init, dtype=np.float64)\n",
    "        self.method = method\n",
    "        self.tol = tol\n",
    "        self.max_step = max_step\n",
    "\n",
    "        self.solution_trajectory = [self.x_init.copy()]\n",
    "        self.directions = []\n",
    "\n",
    "        x_val = np.copy(self.x_init)\n",
    "\n",
    "        for _ in range(self.max_step):\n",
    "            grad = self.grad_f(x_val).full().flatten()\n",
    "            hess = self.hess_f(x_val).full()\n",
    "\n",
    "            # Search direction\n",
    "            if self.method == 'gd':\n",
    "                direction = -grad\n",
    "            elif self.method == 'newton':\n",
    "                direction = -np.linalg.solve(hess + 1e-8*np.eye(2), grad)\n",
    "            else:\n",
    "                raise ValueError(\"Method must be 'gd' or 'newton'\")\n",
    "\n",
    "            descent = grad @ direction\n",
    "            if abs(descent) < self.tol:\n",
    "                break\n",
    "\n",
    "            # Line search (backtracking)\n",
    "            alpha = self.alpha_0\n",
    "            f0 = float(self.f(x_val))\n",
    "            while float(self.f(x_val + alpha * direction)) > f0 + self.c * alpha * descent:\n",
    "                alpha *= self.beta\n",
    "            \n",
    "            # Update\n",
    "            x_val = x_val + alpha * direction\n",
    "            self.solution_trajectory.append(x_val.copy())\n",
    "            self.directions.append(direction.copy())\n",
    "\n",
    "    def plot_results(self):\n",
    "        sol = np.array(self.solution_trajectory)\n",
    "\n",
    "        x_max = max(5, np.max(sol[:, 0]))\n",
    "        x_min = min(-5, np.min(sol[:, 0]))\n",
    "        y_max = max(5, np.max(sol[:, 1]))\n",
    "        y_min = min(-5, np.min(sol[:, 1]))\n",
    "\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.f(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        # Global Optima\n",
    "        ax.plot(self.global_minima[0], self.global_minima[1], marker='*', markersize=15,\n",
    "                color='red', label='Global Optima', zorder=10)\n",
    "\n",
    "        # Optimization Trajectory\n",
    "        ax.plot(sol[:, 0], sol[:, 1], marker='o', markersize=4,\n",
    "                color='orange', label='Trajectory', zorder=10)\n",
    "        ax.plot(sol[0, 0], sol[0, 1], 'bo', label='Start', zorder=11)\n",
    "        ax.plot(sol[-1, 0], sol[-1, 1], 'gs', label='End', zorder=11)\n",
    "\n",
    "        ax.set_title(f'Optimization Trajectory with {self.func_flag.capitalize()} Function')\n",
    "        ax.set_xlabel('x1')\n",
    "        ax.set_ylabel('x2')\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b9ba3",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 1.2: use gradient-descent method to optimize quadratic objective function**\n",
    "\n",
    "Starting with a simple scenario, we first attempt to solve the quadratic objective function using the above unconstrained optimization algorithms. The quadratic function is a simple convex function, and thus can be directly optimized using Gradient Descent. The steps are as follows:\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`(the default parameter settings can be used directly);\n",
    "\n",
    "2\\) Set the objective function to be `quadratic`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `gd` and other solver parameters as follows;\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c7012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic cost + GD solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('quadratic')\n",
    "opt.solve(x_init=[-3, 3], method='gd', max_step=100)\n",
    "opt.plot_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7bad5",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This figure illustrates the performance of GD in optimizing a quadratic objective function. Since quadratic functions are strongly convex with smooth curvature, GD ensures global convergence and follows a stable descent path. The trajectory steadily approaches the global minimum at the origin, demonstrating GD’s efficiency, especially when the Hessian has a well-conditioned structure. The log-scaled contour lines highlight the rapid cost reduction in early iterations and the slower convergence near the minimum, underscoring the importance of step size adaptation strategies like backtracking.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe79d1",
   "metadata": {},
   "source": [
    "##### **Example 1.3: use gradient descent method to optimize Rosenbrock objective function**\n",
    "\n",
    "Now let us consider a more challenging scenario by choosing the Rosenbrock function as the objective. Its global minimum lies at $[1.0,0.0]$, but the function is notoriously difficult to optimize due to its narrow, curved valley and steep walls, which can easily mislead simple gradient-based methods. We will attempt to optimize it using GD and observe the resulting behavior.\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`;\n",
    "\n",
    "2\\) Set the objective function to be `rosenbrock`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `gd` and the maximal step number to be 2000~5000;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Hint: you may try the maximal step number for both lower and upper limit, which will lead to different optimization results*\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock cost + GD solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('rosenbrock')\n",
    "opt.solve(x_init=[-3.0, 3.0], method='gd', max_step=2000)  # max_step: 2000 TO 5000\n",
    "opt.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6971f",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This figure shows the optimization trajectory of gradient descent applied to the Rosenbrock function over 2000 iterations. Due to the function’s narrow, curved valley and sharp gradients across directions, GD initially struggles to follow the optimal path and exhibits zigzag behavior as it gradually aligns with the valley floor. The trajectory eventually begins to converge toward the global minimum, but the progress is much slower compared to optimizing a quadratic function. **This highlights the limitations of GD in ill-conditioned landscapes, where the local curvature causes inefficient updates unless the step size is carefully controlled.** With around 5000 iterations, convergence to the minimum can be achieved, but at a significantly higher computational cost.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e4766",
   "metadata": {},
   "source": [
    "##### **Example 1.4: use Newton method to optimize Rosenbrock objective function**\n",
    "\n",
    "Given the poor performance of GD on the Rosenbrock function, we now attempt to optimize it using Newton’s method. Compared to GD, Newton’s method leverages second-order curvature information, allowing it to take more informed steps and converge faster near the optimum, especially in ill-conditioned landscapes.\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`;\n",
    "\n",
    "2\\) Set the objective function to be `rosenbrock`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `newton` and other solver parameters as follows;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Hint: now you can use a much cmaller number for the maximal step number.*\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock cost + newton solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('rosenbrock')\n",
    "opt.solve(x_init=[-3, 3], method='newton', max_step=100)\n",
    "opt.plot_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524301b",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This figure shows the optimization trajectory of Newton's method applied to the Rosenbrock function. Unlike Gradient Descent, Newton’s method successfully converges to the global optimum at $[1.0,0.0]$ in fewer than 100 iterations, demonstrating significantly higher efficiency. The trajectory closely follows the curved valley, highlighting **Newton's ability to incorporate second-order curvature information for better step directions**, especially in narrow and ill-conditioned landscapes. This result underscores the strength of Newton’s method in adapting to the local geometry of complex objective functions.\n",
    "\n",
    "However, Newton's method also has notable drawbacks when comparing with GD: **it requires computing and inverting the Hessian matrix, which can be computationally expensive and numerically unstable**, especially in high-dimensional problems. Therefore, in practical applications, the choice of direction search algorithm should be guided by the structure and properties of the specific objective function.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf70259",
   "metadata": {},
   "source": [
    "##### **Example 1.5: use Newton method to optimize Rastrigin objective function**\n",
    "\n",
    "Now let us consider a more complex scenario as the testbed for Newton’s method: Rastrigin function, which is highly non-convex and characterized by a large number of regularly spaced local minima, making it particularly challenging for local optimization methods that rely on gradient and curvature information.\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`;\n",
    "\n",
    "2\\) Set the objective function to be `rastrigin`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `newton` and other solver parameters as follows;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Hint: you may try different initializations, which will lead to different optimization results*\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastrigin cost + newton solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('rastrigin')\n",
    "opt.solve(x_init=[-0.8, 3.2], method='newton', max_step=100) # x_init: [-0.8, 3.2] OR [-0.7, 3.3] OR [-0.3, 0.3] OR [-0.2, 0.2]\n",
    "opt.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586058ad",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The experimental results show that when applying Newton’s method to non-convex objective functions, the optimization trajectory is prone to getting trapped in local minima. Moreover, whether the algorithm converges to a global or local optimum largely depends on the initial starting point—Newton’s method typically converges to the nearest stationary point. **This highlights the importance of initialization: the quality of the final solution is highly sensitive to where the optimization begins.**\n",
    "\n",
    "A simple improvement is to use multiple random initializations and select the best outcome among them. Alternatively, momentum-based methods can be introduced to help escape shallow local minima and improve global search capability.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c832be",
   "metadata": {},
   "source": [
    "## ❓mention: not hands-on implementation\n",
    "mention libaraies + parameters\n",
    "\n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f5c42",
   "metadata": {},
   "source": [
    "### **Part (b): constrained optimization**\n",
    "\n",
    "As introduced before, a constrained optimization problem primarily follows the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x} \\quad & f(x) \\\\\n",
    "\\text{subject to} \\quad & h_i(x) = 0, \\quad \\forall i \\in \\{1, 2, \\dots, N\\}, \\\\\n",
    "& g_j(x) \\leq 0, \\quad \\forall j \\in \\{1, 2, \\dots, M\\},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To solve such problems, the **Karush-Kuhn-Tucker (KKT) conditions** provide necessary conditions for optimality under regularity assumptions. The idea is to construct the **Lagrangian**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x, \\lambda, \\mu) = f(x) + \\sum_{i=1}^N \\lambda_i h_i(x) + \\sum_{j=1}^M \\mu_j g_j(x),\n",
    "$$\n",
    "\n",
    "and then enforce the following **KKT conditions**:\n",
    "\n",
    "- **Stationarity**:\n",
    "   $$\n",
    "   \\nabla_x \\mathcal{L}(x^*, \\lambda^*, \\mu^*) = 0\n",
    "   $$\n",
    "\n",
    "- **Primal feasibility**:\n",
    "   $$\n",
    "   h_i(x^*) = 0, \\quad \\forall i, \\qquad g_j(x^*) \\leq 0, \\quad \\forall j\n",
    "   $$\n",
    "\n",
    "- **Dual feasibility**:\n",
    "   $$\n",
    "   \\mu_j^* \\geq 0, \\quad \\forall j\n",
    "   $$\n",
    "\n",
    "- **Complementary slackness**:\n",
    "   $$\n",
    "   \\mu_j^* \\cdot g_j(x^*) = 0, \\quad \\forall j\n",
    "   $$\n",
    "\n",
    "Together, these conditions characterize candidate optimal solutions for constrained nonlinear programming problems.\n",
    "\n",
    "Although the KKT conditions characterize optimal solutions for constrained optimization problems, they cannot be directly used to solve QP or NLP problems without additional numerical strategies. Specifically:\n",
    "\n",
    "- **KKT conditions are not algorithms** — they provide necessary optimality conditions but do not specify how to compute the solution.\n",
    "\n",
    "- **The KKT system itself can be complex** — even in QP problems, solving the KKT conditions leads to a linear system with complementarity constraints, which requires specialized numerical methods.\n",
    "\n",
    "- **In SQP, KKT conditions are approximated iteratively** — each SQP iteration constructs a local QP subproblem using linearized constraints and a quadratic approximation of the cost, and solving this subproblem involves solving the KKT system numerically.\n",
    "\n",
    "- **Modern solvers encapsulate the KKT logic internally** — tools like `qpOASES`, `OSQP`, and `Ipopt` handle all KKT-related computations, allowing users to focus on modeling rather than solver internals.\n",
    "\n",
    "Thus, while the KKT framework underlies QP and SQP theory, practical solution requires converting the conditions into structured numerical subproblems and solving them with dedicated algorithms and solvers, which we will introduce in the following sections.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210aeab",
   "metadata": {},
   "source": [
    "#### **Example 2.1: configurate the solver for QP problems**  \n",
    "\n",
    "\n",
    "Let us first consider a simple variant of the nonlinear programming (NLP) problem: the quadratic programming (QP) problem. A QP problem is defined as an optimization problem where the objective function is quadratic and the constraints are linear. It follows the standard form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\bm{x}} \\quad & \\frac{1}{2} \\bm{x}^\\top \\bm{H} \\bm{x} + \\bm{q}^\\top \\bm{x} \\\\\n",
    "\\text{s.t.} \\quad & \\bm{A}_{\\text{eq}} \\bm{x} = \\bm{b}_{\\text{eq}}\\\\\n",
    "                  & \\bm{A}_{\\text{ineq}} \\bm{x} \\leq \\bm{b}_{\\text{ineq}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $\\bm{H} \\in \\mathbb{R}^{n \\times n}$ is a symmetric matrix defining the curvature of the cost, and $\\bm{g} \\in \\mathbb{R}^n$ defines the linear component of the cost. The matrices $\\bm{A}_{\\text{eq}} \\in \\mathbb{R}^{N \\times n}, \\bm{b}_{\\text{eq}} \\in \\mathbb{R}^{N}, \\bm{A}_{\\text{ineq}}\\in \\mathbb{R}^{M \\times n},$ and $\\bm{b}_{\\text{ineq}} \\in \\mathbb{R}^{M}$ describe the equality and inequality constraints, respectively.\n",
    "\n",
    "Quadratic programming (QP) problems can be solved by deriving and solving the associated Karush-Kuhn-Tucker (KKT) conditions. With the advancement of symbolic and numerical computing tools, modern QP solvers such as **OSQP** and **qpOASES** have automated this process. These solvers internally construct and solve the KKT system, allowing users to simply specify the objective function, constraints, and relevant optimization parameters through a well-defined interface.\n",
    "\n",
    "In this section, we choose **qpOASES** as the QP solver to demonstrate how to configure and use its interface for solving QP problems. It is worth noting that qpOASES is natively supported by CasADi, which allows it to be directly specified as the underlying QP solver within a CasADi-based optimization setup without requiring any separate package installation. The procedure follows the steps below:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1\\) Formulate the QP problem from external.** The standard form of a QP problem supported by CasADi is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\bm{x}} \\quad & \\frac{1}{2} \\bm{x}^\\top \\bm{H} \\bm{x} + \\bm{q}^\\top \\bm{x} \\\\\n",
    "\\text{s.t.} \\quad & \\bm{l}_{\\text{bg}} \\leq \\bm{A} \\bm{x} \\leq \\bm{u}_{\\text{bg}},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $\\bm{A} =\n",
    "\\begin{bmatrix}\n",
    "\\bm{A}_{\\text{eq}} & \\bm{0} \\\\\n",
    "\\bm{0} & \\bm{A}_{\\text{ineq}}\n",
    "\\end{bmatrix}$ defines linear constraints (inkl. equality and inequality constraints) with lower and upper bounds $\\bm{l}_{\\text{bg}} = \\begin{bmatrix}\n",
    "\\bm{b}_{\\text{eq}} \\\\\n",
    "-\\infty\n",
    "\\end{bmatrix}, \\quad\n",
    "\\bm{u}_{\\text{bg}} = \\begin{bmatrix}\n",
    "\\bm{b}_{\\text{eq}} \\\\\n",
    "\\bm{b}_{\\text{ineq}}\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2\\) Define the QP structure in CasADi.** To pass the QP into CasADi, you need to define a dictionary containing:\n",
    "\n",
    "$$\n",
    "\\texttt{qp = \\{x: }\\bm{x}\\texttt{, f: }f(\\bm{x})\\texttt{, g: }g(\\bm{x})\\texttt{\\}},\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $f(\\bm{x})=\\frac{1}{2} \\bm{x}^\\top \\bm{H} \\bm{x} + \\bm{q}^\\top \\bm{x} $ is the quadratic objective and $g(\\bm{x}) = \\bm{A} \\bm{x}$ represents the constraint expressions.\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3\\) Configure and call the solver.** Create and configure the solver using:\n",
    "\n",
    "$$\n",
    "\\texttt{solver = nlpsol(\"solver\", \"qpoases\", qp)},\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and called with the necessary constraint bounds and initial guess:\n",
    "\n",
    "$$\n",
    "\\texttt{sol = solver(x0, lbg, ubg)}.\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The optimal solution can then be extracted from the returned dictionary.\n",
    "\n",
    "*Note that: for the QP solver in CasADi, please check out this material https://web.casadi.org/docs/#quadratic-programming*  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinConstrOptimizer:\n",
    "    def __init__(self):\n",
    "        self.x = ca.MX.sym('x', 2)\n",
    "        self.set_objective()\n",
    "        self.eq_params = None\n",
    "        self.ineq_params = None\n",
    "        self.optimum = None\n",
    "\n",
    "    def set_objective(self):\n",
    "        self.expr = 0.5 * (self.x[0]**2 / 4 + self.x[1]**2)\n",
    "        self.f = ca.Function('f', [self.x], [self.expr])\n",
    "        self.global_minima = np.array([0.0, 0.0])\n",
    "\n",
    "    def set_constraints(self, eq_params=None, ineq_params=None):\n",
    "        self.eq_params = eq_params\n",
    "        self.ineq_params = ineq_params\n",
    "\n",
    "    def solve(self, x_init=[0.0, 0.0]):\n",
    "\n",
    "        A_list = []\n",
    "        lba = []\n",
    "        uba = []\n",
    "\n",
    "        if self.eq_params:\n",
    "            a, b, c = self.eq_params\n",
    "            A_list.append(np.array([[a, b]]))\n",
    "            lba.append(-c)\n",
    "            uba.append(-c)\n",
    "\n",
    "        if self.ineq_params:\n",
    "            a, b, c = self.ineq_params\n",
    "            A_list.append(np.array([[a, b]]))\n",
    "            lba.append(-np.inf)\n",
    "            uba.append(-c)\n",
    "\n",
    "        A_total = np.vstack(A_list) if A_list else np.zeros((0, 2))\n",
    "        lba = np.array(lba)\n",
    "        uba = np.array(uba)\n",
    "\n",
    "        qp = {\n",
    "            'x': self.x,\n",
    "            'f': self.expr,\n",
    "            'g': ca.mtimes(ca.DM(A_total), self.x)\n",
    "        }\n",
    "        \n",
    "        solver = ca.qpsol('solver', 'qpoases', qp)\n",
    "\n",
    "        sol = solver(x0=x_init, lbg=lba, ubg=uba)\n",
    "\n",
    "        self.optimum = sol['x'].full().flatten()\n",
    "        \n",
    "        return self.optimum.tolist()\n",
    "\n",
    "    def plot_results(self):\n",
    "        x_max = 2.5\n",
    "        x_min = -2.5\n",
    "        y_max = 2.5\n",
    "        y_min = -2.5\n",
    "\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.f(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        if self.eq_params:\n",
    "            a, b, c = self.eq_params\n",
    "            if b != 0:\n",
    "                x_eq = np.linspace(x_min, x_max, 400)\n",
    "                y_eq = (-a * x_eq - c) / b\n",
    "                ax.plot(x_eq, y_eq, 'k--', linewidth=2, label='Equality Constraint')\n",
    "            else:\n",
    "                x_eq = -c / a\n",
    "                ax.axvline(x_eq, color='k', linestyle='--', linewidth=2, label='Equality Constraint')\n",
    "\n",
    "        if self.ineq_params:\n",
    "            a, b, c = self.ineq_params\n",
    "            if b != 0:\n",
    "                x_ineq = np.linspace(x_min, x_max, 400)\n",
    "                y_ineq = (-a * x_ineq - c) / b\n",
    "                ax.plot(x_ineq, y_ineq, 'b-', linewidth=2, label='Inequality Constraint')\n",
    "                ax.fill_between(x_ineq, y_ineq, y_max, color='blue', alpha=0.1)\n",
    "            else:\n",
    "                x_ineq = -c / a\n",
    "                ax.axvline(x_ineq, color='b', linestyle='-', linewidth=2, label='Inequality Constraint')\n",
    "                if a > 0:\n",
    "                    ax.axvspan(x_min, x_ineq, color='blue', alpha=0.1)\n",
    "                else:\n",
    "                    ax.axvspan(x_ineq, x_max, color='blue', alpha=0.1)\n",
    "\n",
    "        if self.optimum is not None:\n",
    "            ax.plot(self.optimum[0], self.optimum[1], 'gs', markersize=10, label='Optimal Point', zorder=11)\n",
    "\n",
    "        ax.plot(self.global_minima[0], self.global_minima[1], '*', color='red', markersize=15, label='Global Min')\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_xlabel('$x_0$')\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_title(\"Constrained Optimization Result (QPOASES)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ceacac",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 2.2: use QP solver to optimize quadratic objective function with linear constraint**\n",
    "\n",
    "❓steps + formulation of constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qpOASES for QP\n",
    "opt = LinConstrOptimizer()\n",
    "opt.set_constraints(eq_params=(1, 1, -1), ineq_params=(1, -1, 0))\n",
    "opt.solve(x_init=[0.0, 1.0])\n",
    "opt.plot_results()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1cb8e",
   "metadata": {},
   "source": [
    "#### **Example 3.1: configurate the solver for NLP problems**  \n",
    "\n",
    "\n",
    "\n",
    "❓introduce: SQP -> SQP solver\n",
    "\n",
    "\n",
    "The configuration of a SQP solver is similar to the QP solver, which follows the steps:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1) Formulate the NLP problem.** The standard form of a generic nonlinear programming (NLP) problem is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\bm{x}} \\quad & f(\\bm{x}) \\\\\n",
    "\\text{s.t.} \\quad & \\bm{h}(\\bm{x}) = \\bm{0}, \\\\\n",
    "                  & \\bm{g}(\\bm{x}) \\leq \\bm{0},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $ f(\\bm{x}) $ is a nonlinear cost function, $ \\bm{h}(\\bm{x}) $ defines equality constraints, and $ \\bm{g}(\\bm{x}) $ defines inequality constraints.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2) Define the NLP structure in CasADi.** To pass the NLP into CasADi, you need to define a dictionary:\n",
    "\n",
    "$$\n",
    "\\texttt{nlp = \\{x: } \\bm{x} \\texttt{, f: } f(\\bm{x}) \\texttt{, g: } \\bm{c}(\\bm{x}) \\texttt{\\}},\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $ \\bm{x} \\in \\mathbb{R}^n $ is the optimization variable, $ f(\\bm{x}) $ is the cost function, and $ \\bm{c}(\\bm{x}) $ combines all constraints:\n",
    "\n",
    "$$\n",
    "\\bm{c}(\\bm{x}) =\n",
    "\\begin{bmatrix}\n",
    "\\bm{h}(\\bm{x}) \\\\\n",
    "\\bm{g}(\\bm{x})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The corresponding lower and upper bounds are:\n",
    "\n",
    "$$\n",
    "\\bm{l}_c =\n",
    "\\begin{bmatrix}\n",
    "\\bm{0} \\\\\n",
    "-\\infty\n",
    "\\end{bmatrix}, \\quad\n",
    "\\bm{u}_c =\n",
    "\\begin{bmatrix}\n",
    "\\bm{0} \\\\\n",
    "\\bm{0}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3) Configure and call the solver.** Create the SQP solver by specifying the backend as `\"sqpmethod\"`:\n",
    "\n",
    "$$\n",
    "\\texttt{solver = nlpsol(\"solver\", \"sqpmethod\", nlp)}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Then solve the problem with an initial guess and the constraint bounds:\n",
    "\n",
    "$$\n",
    "\\texttt{sol = solver(x0, lbg = } \\bm{l}_c \\texttt{, ubg = } \\bm{u}_c \\texttt{)}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The optimal solution can be extracted from `sol['x']`.\n",
    "\n",
    "*Note that: for the NLP solver in CasADi, please check out this material https://web.casadi.org/docs/#nonlinear-programming.*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQPOptimizer:\n",
    "    def __init__(self, objective_func, eq_func=None, ineq_func=None, global_minima=None):\n",
    "        self.objective_func = objective_func\n",
    "        self.eq_func = eq_func\n",
    "        self.ineq_func = ineq_func\n",
    "        self.global_minima = np.array(global_minima) if global_minima is not None else None\n",
    "\n",
    "        self.x_dim = self.objective_func.size_in(0)[0]\n",
    "        self.x_start = None\n",
    "        self.x_end = None\n",
    "        self._setup_nlp()\n",
    "\n",
    "    def _setup_nlp(self):\n",
    "        x = ca.MX.sym('x', self.x_dim)\n",
    "        cost = self.objective_func(x)\n",
    "\n",
    "        constraints = []\n",
    "        lbg = []\n",
    "        ubg = []\n",
    "\n",
    "        if self.eq_func is not None:\n",
    "            eq_expr = self.eq_func(x)\n",
    "            constraints.append(eq_expr)\n",
    "            lbg.append(np.zeros(eq_expr.shape[0]))\n",
    "            ubg.append(np.zeros(eq_expr.shape[0]))\n",
    "\n",
    "        if self.ineq_func is not None:\n",
    "            ineq_expr = self.ineq_func(x)\n",
    "            constraints.append(ineq_expr)\n",
    "            lbg.append(-np.inf * np.ones(ineq_expr.shape[0]))\n",
    "            ubg.append(np.zeros(ineq_expr.shape[0]))\n",
    "\n",
    "        if constraints:\n",
    "            g = ca.vertcat(*constraints)\n",
    "            self.lbg = np.concatenate(lbg)\n",
    "            self.ubg = np.concatenate(ubg)\n",
    "        else:\n",
    "            g = ca.MX()\n",
    "            self.lbg = np.array([])\n",
    "            self.ubg = np.array([])\n",
    "\n",
    "        self.x_sym = x\n",
    "        self.nlp = {'x': x, 'f': cost, 'g': g}\n",
    "        self.solver = ca.nlpsol('solver', 'sqpmethod', self.nlp, {'qpsol': 'qrqp', 'print_time': 0})\n",
    "\n",
    "    def solve(self, x_init):\n",
    "        x_init = np.array(x_init).flatten()\n",
    "        self.x_start = x_init.copy()\n",
    "\n",
    "        sol = self.solver(x0=x_init, lbg=self.lbg, ubg=self.ubg)\n",
    "        self.x_end = np.array(sol['x'].full()).flatten()\n",
    "\n",
    "        return self.x_end\n",
    "    \n",
    "    def plot_results(self):\n",
    "        x_max, x_min, y_max, y_min = 2.5, -2.5, 2.5, -2.5\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.objective_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        # Inequality constraint\n",
    "        if self.ineq_func is not None:\n",
    "            G_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    G_vals[i, j] = self.ineq_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, G_vals, levels=[0], colors='b', linewidths=2)\n",
    "            ax.contourf(X, Y, G_vals, levels=[-np.inf, 0], colors='blue', alpha=0.1)\n",
    "\n",
    "        # Equality constraint\n",
    "        if self.eq_func is not None:\n",
    "            H_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    H_vals[i, j] = self.eq_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, H_vals, levels=[0], colors='k', linewidths=2, linestyles='--')\n",
    "\n",
    "        # Plot optimal point\n",
    "        if self.x_end is not None:\n",
    "            ax.plot(self.x_end[0], self.x_end[1], 'gs', markersize=10, label='Optimal Point', zorder=11)\n",
    "\n",
    "        # Plot known global minimum\n",
    "        if self.global_minima is not None:\n",
    "            ax.plot(self.global_minima[0], self.global_minima[1], '*', color='red', markersize=15, label='Global Min')\n",
    "\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_xlabel('$x_0$')\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_title(\"SQP (sqpmethod) Optimization Result\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad41d76",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 3.2: use SQP solver to optimize quadratic objective function with nonlinear constraint**\n",
    "\n",
    "❓steps + formulation of constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e22dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ca.MX.sym('x', 2)\n",
    "f = ca.Function(\"f\", [x], [0.5 * (x[0]**2 / 4 + x[1]**2)])\n",
    "\n",
    "g = ca.Function(\"g\", [x], [(x[0] - 1)**2 + (x[1] - 1.5)**2 * 3 - 1])  # g(x) <= 0\n",
    "h = None  \n",
    "\n",
    "sqp_solver = SQPOptimizer(\n",
    "    objective_func=f,\n",
    "    eq_func=h,\n",
    "    ineq_func=g,\n",
    "    global_minima=[0, 0]\n",
    ")\n",
    "\n",
    "sol = sqp_solver.solve([1.2, 1.6])\n",
    "sqp_solver.plot_results()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
